{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-18T12:41:08.111983Z",
     "start_time": "2019-03-18T12:41:07.807007Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-18T12:42:05.421023Z",
     "start_time": "2019-03-18T12:42:05.413956Z"
    }
   },
   "outputs": [],
   "source": [
    "# Lstm takes continues inputs and generates similar outputs\n",
    "input_dim = 3; hidden_dim = 15;\n",
    "lstm = nn.LSTM(input_dim, hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-17T18:14:38.254620Z",
     "start_time": "2019-03-17T18:14:38.248882Z"
    }
   },
   "outputs": [],
   "source": [
    "T = 5 # time sequence (length of your input)\n",
    "B = 1 # minibatching (batchsize)\n",
    "inputs = [torch.randn(1, 3) for _ in range(T)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-17T18:14:43.980932Z",
     "start_time": "2019-03-17T18:14:43.958816Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 0.2077, -0.2828, -1.9625]]),\n",
       " tensor([[-0.4703, -1.3428,  0.8899]]),\n",
       " tensor([[-0.3735, -0.6493, -0.5404]]),\n",
       " tensor([[0.8666, 0.2921, 1.0045]]),\n",
       " tensor([[0.3367, 0.5125, 0.2508]])]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-17T18:17:01.503222Z",
     "start_time": "2019-03-17T18:17:01.496213Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[0].view(1,1,-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-17T18:17:18.901326Z",
     "start_time": "2019-03-17T18:17:18.879623Z"
    }
   },
   "outputs": [],
   "source": [
    "outputs1 = [];\n",
    "# hiddens1 contains tuple (hidden, cell) and the hidden and outputs[i]\n",
    "# is the same thing\n",
    "hiddens1 = []; \n",
    "hidden = (torch.zeros(1,1, hidden_dim), torch.zeros(1,1, hidden_dim)) \n",
    "for i in inputs:\n",
    "    out, hidden = lstm(i.view(1, 1, -1), hidden)\n",
    "    outputs1.append(out)\n",
    "    hiddens1.append(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[ 0.1478,  0.2600,  0.0446, -0.0169,  0.0901,  0.2062, -0.0220,\n",
       "           -0.1475,  0.0499, -0.0675,  0.1146,  0.0175, -0.0764,  0.0253,\n",
       "            0.0108]]], grad_fn=<StackBackward>),\n",
       " tensor([[[ 0.0871,  0.2050, -0.1235, -0.0213,  0.1463,  0.0848, -0.0386,\n",
       "            0.1302, -0.0125,  0.0522, -0.0305, -0.0091, -0.0646, -0.0845,\n",
       "           -0.0519]]], grad_fn=<StackBackward>),\n",
       " tensor([[[ 0.1444,  0.2415, -0.1053, -0.0230,  0.1536,  0.1646, -0.0571,\n",
       "            0.0873, -0.0293,  0.0263, -0.0114,  0.0080, -0.0810, -0.0702,\n",
       "           -0.0443]]], grad_fn=<StackBackward>),\n",
       " tensor([[[ 0.1530,  0.0560, -0.1864, -0.0632,  0.1551,  0.1467, -0.0825,\n",
       "            0.0973, -0.0627,  0.0573, -0.0340,  0.1303, -0.0631, -0.0486,\n",
       "           -0.0139]]], grad_fn=<StackBackward>),\n",
       " tensor([[[ 0.1905,  0.0548, -0.1417, -0.0999,  0.1631,  0.1756, -0.1008,\n",
       "            0.0804, -0.0914,  0.0246, -0.0198,  0.1679, -0.0693, -0.0275,\n",
       "           -0.0089]]], grad_fn=<StackBackward>)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([[[ 0.1478,  0.2600,  0.0446, -0.0169,  0.0901,  0.2062, -0.0220,\n",
       "            -0.1475,  0.0499, -0.0675,  0.1146,  0.0175, -0.0764,  0.0253,\n",
       "             0.0108]]], grad_fn=<StackBackward>),\n",
       "  tensor([[[ 0.2571,  0.4093,  0.0921, -0.0333,  0.2826,  0.4099, -0.0415,\n",
       "            -0.2149,  0.0890, -0.1707,  0.2135,  0.0298, -0.1373,  0.0509,\n",
       "             0.0251]]], grad_fn=<StackBackward>)),\n",
       " (tensor([[[ 0.0871,  0.2050, -0.1235, -0.0213,  0.1463,  0.0848, -0.0386,\n",
       "             0.1302, -0.0125,  0.0522, -0.0305, -0.0091, -0.0646, -0.0845,\n",
       "            -0.0519]]], grad_fn=<StackBackward>),\n",
       "  tensor([[[ 0.1688,  0.3646, -0.2895, -0.0542,  0.3098,  0.1812, -0.0989,\n",
       "             0.2227, -0.0218,  0.1045, -0.0584, -0.0153, -0.1405, -0.1292,\n",
       "            -0.0920]]], grad_fn=<StackBackward>)),\n",
       " (tensor([[[ 0.1444,  0.2415, -0.1053, -0.0230,  0.1536,  0.1646, -0.0571,\n",
       "             0.0873, -0.0293,  0.0263, -0.0114,  0.0080, -0.0810, -0.0702,\n",
       "            -0.0443]]], grad_fn=<StackBackward>),\n",
       "  tensor([[[ 0.2649,  0.4275, -0.2311, -0.0516,  0.3906,  0.3395, -0.1272,\n",
       "             0.1367, -0.0501,  0.0571, -0.0209,  0.0141, -0.1687, -0.1233,\n",
       "            -0.0849]]], grad_fn=<StackBackward>)),\n",
       " (tensor([[[ 0.1530,  0.0560, -0.1864, -0.0632,  0.1551,  0.1467, -0.0825,\n",
       "             0.0973, -0.0627,  0.0573, -0.0340,  0.1303, -0.0631, -0.0486,\n",
       "            -0.0139]]], grad_fn=<StackBackward>),\n",
       "  tensor([[[ 0.2328,  0.1077, -0.3108, -0.2196,  0.3273,  0.2914, -0.2092,\n",
       "             0.1842, -0.1367,  0.1192, -0.0903,  0.2570, -0.1341, -0.0718,\n",
       "            -0.0254]]], grad_fn=<StackBackward>)),\n",
       " (tensor([[[ 0.1905,  0.0548, -0.1417, -0.0999,  0.1631,  0.1756, -0.1008,\n",
       "             0.0804, -0.0914,  0.0246, -0.0198,  0.1679, -0.0693, -0.0275,\n",
       "            -0.0089]]], grad_fn=<StackBackward>),\n",
       "  tensor([[[ 0.3019,  0.1016, -0.2445, -0.2927,  0.3416,  0.3415, -0.2479,\n",
       "             0.1454, -0.1807,  0.0501, -0.0477,  0.3413, -0.1480, -0.0456,\n",
       "            -0.0160]]], grad_fn=<StackBackward>))]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hiddens1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-17T18:17:19.485348Z",
     "start_time": "2019-03-17T18:17:19.480523Z"
    }
   },
   "outputs": [],
   "source": [
    "len(outputs1) # ths should be equal to sequence (5)\n",
    "outputs1[0].shape\n",
    "# You expect all the time sequence hiddens are equal\n",
    "for i in range(T):\n",
    "    k = (hiddens1[i][0] == outputs1[i]).sum() \n",
    "    assert k == 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-17T18:17:22.925203Z",
     "start_time": "2019-03-17T18:17:22.915625Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1, 3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_input = torch.cat(inputs).view(len(inputs),1, -1)\n",
    "# as you can see the dimension are seq_len, batch, input_size\n",
    "cat_input.shape # this is what you should do in your case as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T21:43:35.079929Z",
     "start_time": "2019-03-14T21:43:35.072657Z"
    }
   },
   "outputs": [],
   "source": [
    "hidden=(torch.zeros(1,1, hidden_dim), torch.zeros(1,1, hidden_dim))\n",
    "out2, hidden2 = lstm(cat_input, hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T21:45:59.707872Z",
     "start_time": "2019-03-14T21:45:59.699672Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(15)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out2.shape # seq_len, batch, hidden_dim (5,1,128) contains all hiddens\n",
    "hidden2[0].shape # 1,1,128 'caz it is only final hidden \n",
    "(hidden2[0] == out2[-1,:,:]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T21:47:31.756179Z",
     "start_time": "2019-03-14T21:47:31.748476Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(15)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this shows us that both cases calculate the same output\n",
    "(hiddens1[-1][0] == hidden2[0]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T22:09:46.280477Z",
     "start_time": "2019-03-14T22:09:46.257742Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(15)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# which one do you need in your thesis\n",
    "_, hidden3 = lstm(cat_input, hidden) # you only need final hidden\n",
    "_, hidden4 = lstm(cat_input)\n",
    "(hidden3[0] == hidden4[0]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T21:58:56.325501Z",
     "start_time": "2019-03-14T21:58:56.316784Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[1, 128]' is invalid for input of size 15",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-a9c6ef7051f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# you need to check linear layer from pytorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[1, 128]' is invalid for input of size 15"
     ]
    }
   ],
   "source": [
    "# you need to reduce the dimenision into 2\n",
    "# you need to check linear layer from pytorch\n",
    "W = torch.randn(hidden_dim, 2)\n",
    "torch.mm(hidden3[0].view(1,128), W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
