{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T21:43:19.921506Z",
     "start_time": "2019-03-14T21:43:19.916730Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T21:43:21.312854Z",
     "start_time": "2019-03-14T21:43:21.305989Z"
    }
   },
   "outputs": [],
   "source": [
    "# Lstm takes continues inputs and generates similar outputs\n",
    "input_dim = 3; hidden_dim= 128;\n",
    "lstm = nn.LSTM(input_dim, hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T21:43:23.656272Z",
     "start_time": "2019-03-14T21:43:23.650840Z"
    }
   },
   "outputs": [],
   "source": [
    "T = 5 # time sequence (length of your input)\n",
    "B = 1 # minibatching (batchsize)\n",
    "inputs=  [torch.randn(1, 3) for _ in range(T)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T21:43:26.141694Z",
     "start_time": "2019-03-14T21:43:26.134868Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 3])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs # this is a training instance\n",
    "inputs[0].view(1,1,-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T21:43:27.821050Z",
     "start_time": "2019-03-14T21:43:27.811160Z"
    }
   },
   "outputs": [],
   "source": [
    "outputs1 = [];\n",
    "# hiddens1 contains tuple (hidden, cell) and the hidden and outputs[i]\n",
    "# is the same thing\n",
    "hiddens1=  []; \n",
    "hidden  =(torch.zeros(1,1, hidden_dim), torch.zeros(1,1, hidden_dim)) \n",
    "for i in inputs:\n",
    "    out, hidden = lstm(i.view(1, 1, -1), hidden)\n",
    "    outputs1.append(out); hiddens1.append(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T21:43:30.874928Z",
     "start_time": "2019-03-14T21:43:30.868503Z"
    }
   },
   "outputs": [],
   "source": [
    "len(outputs1) # ths should be equal to sequence (5)\n",
    "outputs1[0].shape\n",
    "# You expect all the time sequence hiddens are equal\n",
    "for i in range(T):\n",
    "    k = (hiddens1[i][0] == outputs1[i]).sum() \n",
    "    assert k ==128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T21:43:33.190881Z",
     "start_time": "2019-03-14T21:43:33.183774Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1, 3])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_input = torch.cat(inputs).view(len(inputs),1, -1)\n",
    "# as you can see the dimension are seq_len, batch, input_size\n",
    "cat_input.shape # this is what you should do in your case as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T21:43:35.079929Z",
     "start_time": "2019-03-14T21:43:35.072657Z"
    }
   },
   "outputs": [],
   "source": [
    "hidden=(torch.zeros(1,1, hidden_dim), torch.zeros(1,1, hidden_dim))\n",
    "out2, hidden2 = lstm(cat_input, hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T21:45:59.707872Z",
     "start_time": "2019-03-14T21:45:59.699672Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(128)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out2.shape # seq_len, batch, hidden_dim (5,1,128) contains all hiddens\n",
    "hidden2[0].shape # 1,1,128 'caz it is only final hidden \n",
    "(hidden2[0] == out2[-1,:,:]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T21:47:31.756179Z",
     "start_time": "2019-03-14T21:47:31.748476Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(128)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this shows us that both cases calculate the same output\n",
    "(hiddens1[-1][0] == hidden2[0]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T22:09:46.280477Z",
     "start_time": "2019-03-14T22:09:46.257742Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(128)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# which one do you need in your thesis\n",
    "_, hidden3 = lstm(cat_input, hidden) # you only need final hidden\n",
    "_, hidden4 = lstm(cat_input)\n",
    "(hidden3[0] == hidden4[0]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T21:58:56.325501Z",
     "start_time": "2019-03-14T21:58:56.316784Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3600, -0.1191]], grad_fn=<MmBackward>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you need to reduce the dimenision into 2\n",
    "# you need to check linear layer from pytorch\n",
    "W = torch.randn(hidden_dim, 2)\n",
    "torch.mm(hidden3[0].view(1,128), W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
